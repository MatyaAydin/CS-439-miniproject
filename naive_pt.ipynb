{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "2cdbcc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from lab 6:\n",
    "from helper import generate_dataset, visualize_one_dataset, visualize_datasets, predict_grid, visualize_predictions\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "9f81968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def scaling_selection(g, H, sigma, constant_learning_rate=True):\n",
    "\n",
    "    g = g.flatten()\n",
    "    Hg = g#torch.matmul(H, g)\n",
    "    dot_product = torch.dot(g, Hg)\n",
    "    norm_g = torch.norm(g)\n",
    "\n",
    "    if constant_learning_rate:\n",
    "        s_lpc_min = 1 / sigma\n",
    "        s_lpc_max = 1 / sigma\n",
    "    else:\n",
    "        s_lpc_min = (1 / sigma) * torch.rand(1).item()\n",
    "        s_lpc_max = 1 / sigma\n",
    "\n",
    "    s_CG = norm_g**2 / dot_product\n",
    "    s_MR = dot_product / torch.norm(Hg)**2\n",
    "    s_GM = torch.sqrt(s_CG * s_MR)\n",
    "\n",
    "    if dot_product > sigma * norm_g**2:\n",
    "        spc = torch.tensor([s_CG, s_MR, s_GM])[torch.randint(0, 3, (1,)).item()]\n",
    "        return -spc * g, \"SPC\"\n",
    "    elif dot_product > 0 and dot_product < sigma * norm_g**2:\n",
    "        slpc = torch.empty(1).uniform_(s_lpc_min, 1 / sigma).item()\n",
    "        return -slpc * g, \"LPC\"\n",
    "    else:\n",
    "        snc = torch.empty(1).uniform_(s_lpc_min, s_lpc_max).item()\n",
    "        return -snc * g, \"NC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "a274d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#algorithm 3 backward tracking line search\n",
    "\n",
    "def backtracking_LS(model, theta, rho, x, g, p):\n",
    "\n",
    "    alpha = 1.0\n",
    "    while model(x + alpha * p) > model(x) + alpha * rho * torch.dot(g, p):\n",
    "        alpha *= theta\n",
    "\n",
    "\n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "84e9c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm 4 forward/backward tracking line search\n",
    "\n",
    "def forward_backward_LS(model, theta, rho, x, g, p):\n",
    "\n",
    "    g = g.flatten()\n",
    "    p = p.flatten()\n",
    "\n",
    "    alpha = 1.0\n",
    "    if model(x + alpha * p) > model(x) + alpha * rho * torch.dot(g, p):\n",
    "        backtracking_LS(model, theta, rho, x, g, p)\n",
    "    else:\n",
    "        while model(x + alpha * p) >= model(x) + alpha * rho * torch.dot(g, p):\n",
    "            alpha /= theta\n",
    "\n",
    "    return alpha * theta\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "2825e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm 2: scaled gradient descent with line search\n",
    "\n",
    "def scaled_GD_norm_squared(model, x0, sigma, rho, theta_bt, theta_fb, MAX_ITER, eps):\n",
    "    \"\"\"\n",
    "    sigma <<< 1\n",
    "    0 < theta < 1\n",
    "    0 < rho < 1/2\n",
    "    \"\"\"\n",
    "\n",
    "    x_k = x0.clone()\n",
    "    flag_distribution = {\"SPC\": 0, \"LPC\": 0, \"NC\": 0}\n",
    "\n",
    "    for _ in range(MAX_ITER):\n",
    "        g_k = 2 * x_k\n",
    "\n",
    "        if torch.norm(g_k) < eps:\n",
    "            break\n",
    "\n",
    "        # Use identity matrix as Hessian approximation\n",
    "        H_k = torch.eye(len(x_k), dtype=x_k.dtype, device=x_k.device)\n",
    "        p_k, FLAG = scaling_selection(g_k, H_k, sigma)\n",
    "        flag_distribution[FLAG] += 1\n",
    "\n",
    "        if FLAG in [\"SPC\", \"LPC\"]:\n",
    "            alpha_k = backtracking_LS(model, theta_bt, rho, x_k, g_k, p_k)\n",
    "        else:\n",
    "            alpha_k = forward_backward_LS(model, theta_fb, rho, x_k, g_k, p_k)\n",
    "\n",
    "        x_k = x_k + alpha_k * p_k\n",
    "\n",
    "    return x_k, flag_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "b18f29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormSquaredModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.norm(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "00c13676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " {'SPC': 2, 'LPC': 0, 'NC': 0})"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try with ||x||Â² for now\n",
    "model = NormSquaredModel()\n",
    "\n",
    "sigma = 0.1\n",
    "theta_bt = 0.5\n",
    "theta_fb = 0.5\n",
    "rho = 0.25\n",
    "\n",
    "MAX_ITER = 1000\n",
    "eps = 1e-12\n",
    "\n",
    "x_0 = 10 * torch.randn(10)\n",
    "\n",
    "\n",
    "\n",
    "x_star, flag_distribution = scaled_GD_norm_squared(model, x_0, sigma, rho, theta_bt, theta_fb, MAX_ITER, eps)\n",
    "\n",
    "x_star, flag_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "21b42767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must define a classification/regression task and make scaled_gd overwrite torch.optim.Optimizer\n",
    "# https://www.geeksforgeeks.org/custom-optimizers-in-pytorch/\n",
    "\n",
    "class SimpleMLP(torch.nn.Sequential):\n",
    "    def __init__(self, hidden_dim):\n",
    "        self.name = 'NN'\n",
    "        self.num_classes = 2\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: Define your neural network model with ReLU\n",
    "        # HINT: Use torch.nn.Sequential and torch.nn.ReLU\n",
    "        # ***************************************************\n",
    "        super().__init__(\n",
    "            torch.nn.Linear(2, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, self.num_classes),\n",
    "        )\n",
    "        \n",
    "    def init_params(self, train_data):\n",
    "        ''' No need to do anything since it is taken care of by torch.nn.Sequential'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "4cbe169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaled_GD_Optimizer(torch.optim.Optimizer):\n",
    "    def __init__(self, params, sigma, rho, theta_bt, theta_fb):\n",
    "        defaults = dict(sigma=sigma, rho=rho, theta_bt=theta_bt, theta_fb=theta_fb, eps=eps)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure):\n",
    "        loss = closure()\n",
    "\n",
    "        #all parameters\n",
    "        x_k = torch.cat([p.data.flatten() for group in self.param_groups for p in group[\"params\"]])\n",
    "        #compute whole gradient\n",
    "        g_k = torch.cat([\n",
    "            p.grad.data.flatten().clone()\n",
    "            for group in self.param_groups for p in group[\"params\"]\n",
    "            if p.grad is not None\n",
    "        ])\n",
    "\n",
    "        H_k = torch.eye(len(g_k)) # TODO compute hessian\n",
    "        p_k, FLAG = scaling_selection(g_k, H_k, sigma)\n",
    "\n",
    "\n",
    "        \n",
    "        if FLAG in [\"SPC\", \"LPC\"]:\n",
    "            alpha_k = backtracking_LS(lambda x: closure(), theta_bt, rho, x_k, g_k, p_k)\n",
    "        else:\n",
    "            alpha_k = forward_backward_LS(lambda x: closure(), theta_fb, rho, x_k, g_k, p_k)\n",
    "\n",
    "        print(alpha_k)\n",
    "\n",
    "\n",
    "\n",
    "        #update all parameters\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is not None:\n",
    "                    p.data.add_(alpha_k * p.grad)\n",
    "\n",
    "\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "0ef9d2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        with torch.no_grad():\\n            for group in self.param_groups:\\n                sigma = group[\"sigma\"]\\n                rho = group[\"rho\"]\\n                theta_bt = group[\"theta_bt\"]\\n                theta_fb = group[\"theta_fb\"]\\n\\n                for p in group[\\'params\\']:\\n                    if p.grad is None:\\n                        continue\\n\\n                    x_k = p.data.clone()\\n                    g_k = p.grad.data.clone()\\n\\n                    H_k = None\\n\\n                    p_k, FLAG = scaling_selection(g_k, H_k, sigma)\\n\\n                    if FLAG in [\"SPC\", \"LPC\"]:\\n                        alpha_k = backtracking_LS(loss, theta_bt, rho, x_k, g_k, p_k)\\n                    else:\\n                        alpha_k = forward_backward_LS(loss, theta_fb, rho, x_k, g_k, p_k)\\n            \\n                    x_k = x_k + alpha_k * p_k\\n                    p.data.copy_(x_k)\\n'"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "        with torch.no_grad():\n",
    "            for group in self.param_groups:\n",
    "                sigma = group[\"sigma\"]\n",
    "                rho = group[\"rho\"]\n",
    "                theta_bt = group[\"theta_bt\"]\n",
    "                theta_fb = group[\"theta_fb\"]\n",
    "\n",
    "                for p in group['params']:\n",
    "                    if p.grad is None:\n",
    "                        continue\n",
    "\n",
    "                    x_k = p.data.clone()\n",
    "                    g_k = p.grad.data.clone()\n",
    "\n",
    "                    H_k = None\n",
    "\n",
    "                    p_k, FLAG = scaling_selection(g_k, H_k, sigma)\n",
    "\n",
    "                    if FLAG in [\"SPC\", \"LPC\"]:\n",
    "                        alpha_k = backtracking_LS(loss, theta_bt, rho, x_k, g_k, p_k)\n",
    "                    else:\n",
    "                        alpha_k = forward_backward_LS(loss, theta_fb, rho, x_k, g_k, p_k)\n",
    "            \n",
    "                    x_k = x_k + alpha_k * p_k\n",
    "                    p.data.copy_(x_k)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "aaec412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "NUM_SAMPLES = 100\n",
    "\n",
    "blobs_train, blobs_test = generate_dataset(\"blobs\", NUM_SAMPLES)\n",
    "moons_train, moons_test = generate_dataset(\"moons\", NUM_SAMPLES)\n",
    "xor_train, xor_test = generate_dataset(\"xor\", NUM_SAMPLES)\n",
    "squares_train, squares_test = generate_dataset(\"bar\", NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "335c01d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(blobs_train, batch_size=10, shuffle=True)\n",
    "test_loader = data.DataLoader(blobs_test, batch_size=NUM_SAMPLES)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "model = SimpleMLP(hidden_dim=256)\n",
    "optimizer = Scaled_GD_Optimizer(model.parameters(), sigma, rho, theta_bt, theta_fb)\n",
    "\n",
    "\n",
    "sigma = 1e-2\n",
    "theta_bt = 0.5\n",
    "theta_fb = 0.5\n",
    "rho = 0.25\n",
    "N_EPOCH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "8f2290b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "2.384185791015625e-07\n",
      "2.384185791015625e-07\n",
      "0 0.6520826816558838\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "2.384185791015625e-07\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "1.4901161193847656e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "2.384185791015625e-07\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "2.384185791015625e-07\n",
      "1.4901161193847656e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "1.4901161193847656e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "1.4901161193847656e-08\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "1.4901161193847656e-08\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "2.384185791015625e-07\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "1.4901161193847656e-08\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "1.4901161193847656e-08\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "2.384185791015625e-07\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "1.4901161193847656e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "1.4901161193847656e-08\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "2.384185791015625e-07\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "1.4901161193847656e-08\n",
      "1.4901161193847656e-08\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "1.4901161193847656e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "2.384185791015625e-07\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "2.384185791015625e-07\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "2.384185791015625e-07\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "2.384185791015625e-07\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "7.450580596923828e-09\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "1.4901161193847656e-08\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "1.4901161193847656e-08\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "1.4901161193847656e-08\n",
      "7.450580596923828e-09\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "1.4901161193847656e-08\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "2.384185791015625e-07\n",
      "2.384185791015625e-07\n",
      "2.384185791015625e-07\n",
      "1.4901161193847656e-08\n",
      "5.960464477539063e-08\n",
      "2.384185791015625e-07\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "2.384185791015625e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "2.384185791015625e-07\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "2.384185791015625e-07\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "1.4901161193847656e-08\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "1.4901161193847656e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "2.384185791015625e-07\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "7.450580596923828e-09\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "2.384185791015625e-07\n",
      "5.960464477539063e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "1.4901161193847656e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "1.4901161193847656e-08\n",
      "1.1920928955078125e-07\n",
      "2.384185791015625e-07\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.384185791015625e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "1.1920928955078125e-07\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "1.4901161193847656e-08\n",
      "5.960464477539063e-08\n",
      "2.384185791015625e-07\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "2.384185791015625e-07\n",
      "1.1920928955078125e-07\n",
      "1.1920928955078125e-07\n",
      "2.9802322387695312e-08\n",
      "5.960464477539063e-08\n",
      "2.9802322387695312e-08\n",
      "2.9802322387695312e-08\n",
      "1.4901161193847656e-08\n",
      "5.960464477539063e-08\n",
      "1.1920928955078125e-07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[480], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m---> 15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Compute the test loss\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m minibatch, label \u001b[38;5;129;01min\u001b[39;00m test_loader:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m             )\n\u001b[1;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[476], line 7\u001b[0m, in \u001b[0;36mScaled_GD_Optimizer.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure):\n\u001b[1;32m----> 7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#all parameters\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     x_k \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([p\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n",
      "Cell \u001b[1;32mIn[480], line 12\u001b[0m, in \u001b[0;36mclosure\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model(minibatch)\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(prediction, label)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = np.zeros(N_EPOCH)\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    for minibatch, label in train_loader:\n",
    "\n",
    "        label = label.long()\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(minibatch)\n",
    "            loss = loss_fn(prediction, label)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        loss = optimizer.step(closure)\n",
    "\n",
    "    # Compute the test loss\n",
    "    for minibatch, label in test_loader:\n",
    "        label = label.long()\n",
    "        with torch.no_grad():\n",
    "            loss = loss_fn(model(minibatch), label)\n",
    "            losses[epoch] = loss.item()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(epoch, loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6feaa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c38940d750>]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(N_EPOCH), losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
