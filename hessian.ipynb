{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2860849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.functional import hessian\n",
    "from torch.nn.utils.stateless import functional_call\n",
    "\n",
    "def compute_hessian(model: nn.Module, \n",
    "                    x: torch.Tensor, \n",
    "                    y: torch.Tensor, \n",
    "                    loss_fn: callable) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the Hessian of the loss w.r.t. all model parameters.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): PyTorch model\n",
    "        x (torch.Tensor): Input data\n",
    "        y (torch.Tensor): Target data\n",
    "        loss_fn (callable): Loss function that returns scalar (e.g., nn.MSELoss())\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Hessian matrix of shape (N, N), where N is total parameter count\n",
    "    \"\"\"\n",
    "    # Extract and flatten parameters\n",
    "    params = dict(model.named_parameters())\n",
    "    param_shapes = [(name, p.shape) for name, p in params.items()]\n",
    "    flat_params = torch.cat([p.detach().reshape(-1) for p in params.values()]).requires_grad_(True)\n",
    "\n",
    "    # Helper to unflatten flat_params into named parameter dict\n",
    "    def unflatten_params(flat_params):\n",
    "        param_dict = {}\n",
    "        idx = 0\n",
    "        for name, shape in param_shapes:\n",
    "            n = torch.tensor(shape).prod().item()\n",
    "            param_dict[name] = flat_params[idx:idx+n].view(shape)\n",
    "            idx += n\n",
    "        return param_dict\n",
    "\n",
    "    # Loss wrapper for hessian\n",
    "    def wrapped_loss(flat_params):\n",
    "        new_params = unflatten_params(flat_params)\n",
    "        y_pred = functional_call(model, new_params, (x,))\n",
    "        return loss_fn(y_pred, y)\n",
    "\n",
    "    # Compute and return Hessian\n",
    "    return hessian(wrapped_loss, flat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db05bbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hessian test passed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35675/2758171400.py:40: FutureWarning: `torch.nn.utils.stateless.functional_call` is deprecated as of PyTorch 2.0 and will be removed in a future version of PyTorch. Please use `torch.func.functional_call` instead which is a drop-in replacement.\n",
      "  y_pred = functional_call(model, new_params, (x,))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Assume compute_hessian is already defined\n",
    "\n",
    "# Define simple linear model: y = wx + b\n",
    "class SimpleLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def test_hessian_linear():\n",
    "    # Input and target\n",
    "    x_val = 3.0\n",
    "    x = torch.tensor([[x_val]])\n",
    "    y = torch.tensor([[1.0]])\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    def loss_fn(y_pred, y):\n",
    "        return 0.5 * ((y_pred - y) ** 2).mean()\n",
    "\n",
    "\n",
    "    # Model\n",
    "    model = SimpleLinear()\n",
    "    with torch.no_grad():\n",
    "        model.linear.weight.fill_(0.0)\n",
    "        model.linear.bias.fill_(0.0)\n",
    "\n",
    "    # Compute Hessian\n",
    "    H = compute_hessian(model, x, y, loss_fn)\n",
    "\n",
    "    # Expected Hessian:\n",
    "    # d^2L/dw^2 = x^2\n",
    "    # d^2L/dwdb = x\n",
    "    # d^2L/db^2 = 1\n",
    "    x_sq = x_val ** 2\n",
    "    expected = torch.tensor([\n",
    "        [x_sq, x_val],\n",
    "        [x_val, 1.0]\n",
    "    ])\n",
    "\n",
    "    # Compare\n",
    "    H2x2 = H[:2, :2]  # Should be exactly 2 parameters: w and b\n",
    "    assert torch.allclose(H2x2, expected, atol=1e-6), f\"Expected:\\n{expected}\\nGot:\\n{H2x2}\"\n",
    "    print(\"✅ Hessian test passed.\")\n",
    "\n",
    "# Run the test\n",
    "test_hessian_linear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8ddbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
