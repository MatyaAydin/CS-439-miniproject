{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d585b6",
   "metadata": {},
   "source": [
    "### Get plots on multiclass logistic regression on CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4693f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from jax import grad\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from optimizers.mrcg import (\n",
    "    scaling_selection as mrcg_scaling_selection,\n",
    "    backtracking_LS   as mrcg_backtracking,\n",
    "    forward_backward_LS as mrcg_forwardback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e9c4a4",
   "metadata": {},
   "source": [
    "### 1. Data and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae974b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_flatten():\n",
    "    tfm = T.Compose([T.ToTensor()])\n",
    "    ds  = torchvision.datasets.CIFAR10(root=\"~/.torch/datasets\",\n",
    "                                       train=True, download=True, transform=tfm)\n",
    "    X = torch.stack([x.view(-1) for x, _ in ds]).numpy()          # (50k,3072)\n",
    "    y = torch.tensor([lbl for _, lbl in ds]).numpy()              # (50k,)\n",
    "    X = (X - X.mean(0, keepdims=True)) / (X.std(0, keepdims=True) + 1e-6)\n",
    "    X = np.concatenate([X, np.ones((X.shape[0],1))], axis=1)      # +bias feat\n",
    "    return X.astype(np.float32), y.astype(np.int32)\n",
    "\n",
    "X_np, y_np = load_cifar10_flatten()\n",
    "N, d = X_np.shape\n",
    "C     = 10\n",
    "print(f\"Loaded CIFAR-10: X {X_np.shape}, y {y_np.shape}\")\n",
    "\n",
    "# one-hot for *all* 10 classes  (→ first loss = ln 10)\n",
    "Y_onehot = (y_np[:,None] == np.arange(C)[None,:]).astype(np.float32)\n",
    "\n",
    "# JAX arrays\n",
    "X, Y = jnp.asarray(X_np), jnp.asarray(Y_onehot)\n",
    "\n",
    "lambda_ = 1e-3\n",
    "sigma, theta, rho = 0.0, 0.5, 1e-4\n",
    "key = jr.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a694be5",
   "metadata": {},
   "source": [
    "### 2. Define oracle counting identical to report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c2783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_raw(params):\n",
    "    \"\"\"params shape (d*(C-1),) for classes 0…8; class-9 weights are zero.\"\"\"\n",
    "    W = params.reshape(d, C-1)                 # (d,9)\n",
    "    logits  = X @ W                            # (N,9)\n",
    "    ref_col = jnp.zeros((N,1))                 # class-9 logits = 0\n",
    "    full_logits = jnp.concatenate([logits, ref_col], axis=1)  # (N,10)\n",
    "\n",
    "    log_probs = full_logits - jax.scipy.special.logsumexp(\n",
    "                                full_logits, axis=1, keepdims=True)\n",
    "    ce  = -jnp.mean(jnp.sum(Y * log_probs, axis=1))            # NOTE: no slice\n",
    "    reg = 0.5 * lambda_ * jnp.sum(params**2)\n",
    "    return ce + reg\n",
    "\n",
    "oracle_calls = 0\n",
    "def f_counted(p):   # +1\n",
    "    global oracle_calls\n",
    "    oracle_calls += 1\n",
    "    return f_raw(p)\n",
    "\n",
    "def grad_count(p):  # f +1 already, add +1 here  ⇒ 2 total\n",
    "    global oracle_calls\n",
    "    oracle_calls += 1\n",
    "    return grad(f_counted)(p)\n",
    "\n",
    "def hvp_count(p,v): # f+g already, add +2 here  ⇒ 4 total\n",
    "    global oracle_calls\n",
    "    oracle_calls += 2\n",
    "    return jax.jvp(grad(f_counted), (p,), (v,))[1]\n",
    "\n",
    "\n",
    "def ada_hessian_count(g, H_hat):\n",
    "  global oracle_calls\n",
    "  oracle_calls +=1\n",
    "  return (1 / jnp.sqrt(H_hat)) * g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536dd3d5",
   "metadata": {},
   "source": [
    "### 3. Optimizer steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5600a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_hat = jnp.zeros(d*(C-1))\n",
    "p_k = jnp.zeros(d*(C-1))\n",
    "beta = 0.99\n",
    "eps = 1e-9\n",
    "\n",
    "def mrcg_step(state, mode):\n",
    "    \"Performs one step of the MRCG algorithm. mode is a string in [full, square_adahessian, adahessian] that determines which hessian approximation to use.\"\n",
    "    params, key = state\n",
    "    key, sk = jr.split(key)\n",
    "\n",
    "    g = grad_count(params)\n",
    "    if mode == \"full\":\n",
    "        p, flag = mrcg_scaling_selection(\n",
    "          g, lambda p,_: f_counted(p), params, sigma, sk,use_H_hat=False,\n",
    "          hv_fun=lambda p,v: hvp_count(p,v)\n",
    "      )\n",
    "    if mode == \"square_adahessian\":\n",
    "        global H_hat\n",
    "        H_hat = H_hat + jnp.square(g)\n",
    "        p, flag = mrcg_scaling_selection(\n",
    "          g, lambda p,_: f_counted(p), params, sigma, sk,use_H_hat=True, H_hat=H_hat,\n",
    "          hv_fun=lambda g,h: ada_hessian_count(g,h)\n",
    "      )\n",
    "        \n",
    "\n",
    "    if mode == \"adahessian\":\n",
    "        global H_hat\n",
    "        H_hat = H_hat + g\n",
    "        p, flag = mrcg_scaling_selection(\n",
    "          g, lambda p,_: f_counted(p), params, sigma, sk,use_H_hat=True, H_hat=H_hat,\n",
    "          hv_fun=lambda g,h: ada_hessian_count(g,h)\n",
    "      )\n",
    "\n",
    "    # To use momentum:\n",
    "\n",
    "    # global p_k\n",
    "    # p_k = beta * p_k + (1 - beta) * p\n",
    "    # p = p_k # Use momentum\n",
    "\n",
    "    # To use adaptative scaling (must be used with mode == \"full\"):\n",
    "    # global H_hat\n",
    "    # H_hat = beta * H_hat + (1 - beta) * jnp.square(g)\n",
    "    # p /= (jnp.sqrt(H_hat) + eps)\n",
    "\n",
    "    if flag in (\"SPC\",\"LPC\"):\n",
    "        alpha = mrcg_backtracking(lambda p,_: f_counted(p), sk, theta, rho,\n",
    "                              params, g, p)\n",
    "    else:\n",
    "        alpha = mrcg_forwardback(lambda p,_: f_counted(p), sk, theta, rho,\n",
    "                             params, g, p)\n",
    "    return (params + alpha*p, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a92df2f",
   "metadata": {},
   "source": [
    "### 4. Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd70014",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = (jnp.zeros(d*(C-1), jnp.float32), key)\n",
    "MAX_CALLS, GRAD_TOL = 100_000, 1e-4\n",
    "obj, orc = [], []\n",
    "\n",
    "bar = tqdm(total=MAX_CALLS, desc=\"Oracle calls\", unit=\"call\", dynamic_ncols=True)\n",
    "while oracle_calls < MAX_CALLS:\n",
    "    oc_prev = oracle_calls\n",
    "    state   = mrcg_step(state, \"full\")\n",
    "    f_val   = f_counted(state[0])               # +1\n",
    "    g_norm  = jnp.linalg.norm(grad_count(state[0]))  # +1\n",
    "    obj.append(f_val); orc.append(oracle_calls)\n",
    "    bar.update(oracle_calls - oc_prev)\n",
    "    if g_norm <= GRAD_TOL: break\n",
    "bar.close()\n",
    "\n",
    "print(f\"Stopped after {oracle_calls} calls; final ‖g‖={float(g_norm):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f16627",
   "metadata": {},
   "source": [
    "### 5. Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf421d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "fig, ax = plt.subplots(figsize=(4.5,3.8))\n",
    "ax.set_xscale(\"log\")\n",
    "ax.plot(orc, obj, label=\"MRCG\")\n",
    "ax.yaxis.set_major_formatter(mtick.ScalarFormatter(useMathText=True))\n",
    "ax.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "ax.set_xlabel(\"Oracle Calls\"); ax.set_ylabel(\"Objective Value\")\n",
    "ax.grid(True, which=\"both\", lw=0.3); ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"mrcg_cifar10_curve.pdf\", dpi=150)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
